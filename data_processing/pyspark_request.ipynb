{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4023716-f966-4546-9ad2-585904b01e65",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Запуск/Остановка SparkSession\n",
        "try:\n",
        "    spark.stop()\n",
        "    del spark\n",
        "except:\n",
        "    %run configuration.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2813e66c-6669-4510-aa9a-8274d4de6944",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Сборка витрины по расчётным счетам корпоративных клиентов\n",
        "# Обработка данных из разных источников и сохранение результата\n",
        "# в таблицу Hive (на кластер)\n",
        "try:\n",
        "    spark.sql('drop table stor.rko_showcase')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Префикс к таблицам\n",
        "prx_epk: str = 'arn_model_party_organization_'\n",
        "\n",
        "# БД\n",
        "schema: dict = {\n",
        "    'rko': 'with_db_collection_sch_rko_platform_rko',\n",
        "    'epk': 'with_db_collection_sch_epk_platform_uckpb',\n",
        "    'sbbol': 'with_db_collection_vnp_sbbol_birdabi'\n",
        "}\n",
        "\n",
        "# Таблицы\n",
        "table: dict = {\n",
        "    'currency': 'platform_gdp_model_jpa_currency',\n",
        "    'rstatus': 'platform_gdp_model_jpa_rstatus',\n",
        "    'rtype': 'platform_gdp_model_jpa_rtype',\n",
        "    'register': 'platform_gdp_model_jpa_register',\n",
        "    'mregister': 'platform_gdp_model_jpa_mregister',\n",
        "    'sourcesystem': 'platform_gdp_model_jpa_sourcesystem',\n",
        "    'ptarget': 'platform_gdp_model_jpa_ptarget',\n",
        "    'product': 'platform_gdp_model_jpa_product',\n",
        "    'ptype': 'platform_gdp_model_jpa_ptype',\n",
        "    'mproduct': 'platform_gdp_model_jpa_mproduct',\n",
        "    'segment': 'platform_gdp_model_jpa_segment',\n",
        "    'priority': 'platform_gdp_model_jpa_priority',\n",
        "    'country': 'platform_gdp_model_jpa_country',\n",
        "    'org': 'platform_gdp_model_jpa_org',\n",
        "    'orgn': 'platform_gdp_model_jpa_orgn',\n",
        "    'crm': 'platform_gdp_model_jpa_crm',\n",
        "    'ogrn': 'platform_gdp_model_jpa_ogrn',\n",
        "    'inn': 'platform_gdp_model_jpa_inn'\n",
        "}\n",
        "\n",
        "# Валюта счёта\n",
        "currency: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['country']}\")\n",
        "    .select(\n",
        "        F.col('key').alias('currency_key'),\n",
        "        F.col('name').alias('currency_name')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Статус счёта\n",
        "register_status: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['rstatus']}\")\n",
        "    .select(\n",
        "        F.col('key').alias('register_status_key'),\n",
        "        F.col('name').alias('register_status_name')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Тип счёта\n",
        "register_type: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['rtype']}\")\n",
        "    .select(\n",
        "        F.col('key').alias('register_type_key'),\n",
        "        F.col('name').alias('register_type_name')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Счета\n",
        "register: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{['register']}\")\n",
        "    .filter(\n",
        "        (F.to_date(F.col('begindate'))\n",
        "        .between('2024-01-01 00:00:00:000000', '2024-12-31 23:59:60:999999'))\n",
        "        & (F.col('currency_short_foreign_key').like('RUR'))\n",
        "        & (F.col('status_short_foreign_key').isin('Working', 'Closed'))\n",
        "        & (F.col('number').substr(1, 3).isin('401', '402', '404', '405',\n",
        "                                             '406', '407', '408'))\n",
        "        & (F.col('number').substr(1, 5).isin('40109', '40111', '40803',\n",
        "                                             '40810', '40813', '40817',\n",
        "                                             '40820', '40824') == False)\n",
        "    )\n",
        "    .select(\n",
        "        F.col('ownerepkid_entityd').cast(T.StringType()).alias('epk_id'),\n",
        "        F.col('begindate').cast(T.DateType()),\n",
        "        F.col('enddate').cast(T.DateType()),\n",
        "        F.col('lastchangedate').cast(T.DateType()),\n",
        "        F.col('number').cast(T.StringType()),\n",
        "        F.col('currency_short_foreign_key').alias('currency_key'),\n",
        "        F.col('status_short_foreign_key').alias('register_status_key'),\n",
        "        F.col('registertype_short_foreign_key').alias('register_type_key'),\n",
        "        F.col('product_short_foreign_key').alias('product_key'),\n",
        "        F.col('key').alias('register_key')\n",
        "    )\n",
        "    .withColumn(\n",
        "        'diff',\n",
        "        F.datediff(\n",
        "            end=(F.col('enddate')),\n",
        "            start=(F.col('startdate'))\n",
        "        )\n",
        "    )\n",
        "    .filter((F.col('diff') >= F.lit(7)) | (F.col('enddate').isNull()))\n",
        "    .drop('diff')\n",
        "    .join(F.broadcast(currency), on='currency_key',\n",
        "          how='left_outer')\n",
        "    .drop('currency_key')\n",
        "    .join(F.broadcast(register_status), on='register_status_key',\n",
        "          how='left_outer')\n",
        "    .drop('register_status_key')\n",
        "    .join(F.broadcast(register_type), on='register_type_key',\n",
        "        how='left_outer')\n",
        "    .drop('register_type_key')\n",
        ")\n",
        "\n",
        "# Справочник систем источников\n",
        "sourcesystem: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['sourcesystem']}\")\n",
        "    .select(\n",
        "        F.col('objectid').alias('sourcesystem_key'),\n",
        "        F.col('name').alias('sourcesystem_name')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Таблица миграции счетов\n",
        "mregister: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['mregister']}\")\n",
        "    .select(\n",
        "        F.col('eksid').cast(T.StringType()).alias('eks_id'),\n",
        "        F.col('pprbid').cast(T.StringType()).alias('pprb_id'),\n",
        "        F.col('register_entityid').alias('register_key'),\n",
        "        F.col('sourcesystem_short_foreign_key').alias('sourcesystem_key'),\n",
        "        F.col('migratetm').alias('migration_date')\n",
        "    )\n",
        "    .join(register, on='register_key', how='inner')\n",
        "    .drop('register_key')\n",
        "    .join(F.broadcast(sourcesystem), on='sourcesystem_key', how='inner')\n",
        "    .drop('sourcesystem_key')\n",
        ")\n",
        "\n",
        "# Целевое назначение договора РКО\n",
        "producttarget: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['ptarget']}\")\n",
        "    .select(\n",
        "        F.col('description').alias('prod_target'),\n",
        "        F.col('key').alias('key_target')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Вид договора РКО\n",
        "producttype: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['ptype']}\")\n",
        "    .select(\n",
        "        F.col('name').alias('ptype_name'),\n",
        "        F.col('key').alias('ptype_key')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Договор расчётно-кассового обслуживания ЮЛ/ИП\n",
        "product: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['product']}\")\n",
        "    .filter(\n",
        "        F.col('target_short_foreign_key')\n",
        "        .isin(\n",
        "            'CorporateCreditAccount', 'IndividualElectionFunds',\n",
        "            'ElectionCommissionAccount', 'MetalPreciousAccount',\n",
        "            'NotaryDeposit', 'ElectoralAssociationAccount', \n",
        "            'LawEnforcementDepositAccount', 'SpecialBrokerageAccount',\n",
        "            'SpecialDepositaryAccount', 'PrivatePensionReservesAccount',\n",
        "            'PaymentIdentification', 'NominalGuardian48FZ',\n",
        "            'PrivatePensionSavingsAccount', 'ClearingBankAccount',\n",
        "            'CurrentBailiffsServiceDepositAccount', 'IndAccount',\n",
        "            'FundsTemporarityDisposal', 'UFKvalyataAccount'\n",
        "        ) == False\n",
        "    )\n",
        "    .select(\n",
        "        F.col('key').alias('product_key'),\n",
        "        F.col('target_short_foreign_key').alias('key_target'),\n",
        "        F.col('num').cast(T.StringType()).alias('num_dog'),\n",
        "        F.col('producttype_short_foreign_key').alias('ptype_key')\n",
        "    )\n",
        "    .join(F.broadcast(producttarget), on='key_target', how='inner')\n",
        "    .drop('key_target')\n",
        "    .join(F.broadcast(producttype), on='ptype_key', how='left_outer')\n",
        "    .drop('ptype_key')\n",
        "    .join(mregister, on='product_key', how='inner')\n",
        ")\n",
        "\n",
        "# Справочник подразделений банка\n",
        "branch: DataFrame = (\n",
        "    spark.table(f\"{schema['sbbol']}.branch\")\n",
        "    .select(\n",
        "        F.col('fullname').alias('division'),\n",
        "        F.col('sclir').alias('divisionekscode')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Дополнительные атрибуты для РКО из устаревших систем\n",
        "mproduct: DataFrame = (\n",
        "    spark.table(f\"{schema['rko']}.{table['mproduct']}\")\n",
        "    .select(\n",
        "        'divisionekscode',\n",
        "        F.col('product_entityid').cast(T.StringType()).alias('product_key')\n",
        "    )\n",
        "    .join(product, on='product_key', how='right_outer')\n",
        "    .drop('product_key')\n",
        "    .join(branch, on='divisionekscode', how='inner')\n",
        "    .drop('divisionekscode')\n",
        ")\n",
        "\n",
        "# Справочник сегментов\n",
        "dictionary_segment: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{table['segment']}\")\n",
        "    .select(\n",
        "        F.col('name').alias('segment'),\n",
        "        F.col('key').alias('key_segment')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Справочник приоритетов\n",
        "dictionary_priority: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{table['priority']}\")\n",
        "    .select(\n",
        "        F.col('name').alias('priority'),\n",
        "        F.col('key').alias('key_priority')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Справочник стран\n",
        "dictionary_country: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{table['country']}\")\n",
        "    .select(\n",
        "        F.col('name').alias('country_name'),\n",
        "        F.col('key').alias('key_country')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Организации\n",
        "organization: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{table['org']}\")\n",
        "    .select(\n",
        "        F.col('id').cast(T.StringType()).alias('epk_id'),\n",
        "        F.col('key').alias('key_name'),\n",
        "        F.col('countryresident_short_foreign_key').alias('key_country')\n",
        "    )\n",
        "    .join(mproduct, on='epk_id', how='inner')\n",
        ")\n",
        "\n",
        "# Наименование организаций\n",
        "organizationname: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{prx_epk}{table['orgn']}\")\n",
        "    .filter(\n",
        "        F.col('nametype_short_foreign_key').like('NameType_3')\n",
        "    )\n",
        "    .select(\n",
        "        'key',\n",
        "        F.col('name').alias('name_org')\n",
        "    )\n",
        "    .withColumn('key_name', F.split('key', '\\.')[0])\n",
        "    .join(organization, on='key_name', how='inner')\n",
        "    .drop('key')\n",
        ")\n",
        "\n",
        "# CRM-атрибуты\n",
        "crmattributes: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{prx_epk}{table['crm']}\")\n",
        "    .select(\n",
        "        F.col('id').cast(T.StringType()).alias('epk_id'),\n",
        "        F.col('segment_short_foreign_key').alias('key_segment'),\n",
        "        F.col('priority_short_foreign_key').alias('key_priority')\n",
        "    )\n",
        "    .join(organizationname, on='epk_id', how='right_outer')\n",
        ")\n",
        "\n",
        "# ОГРН клиента\n",
        "win_ogrn: any = (\n",
        "    Window.partitionBy('key_name', 'ogrn').orderBy(F.desc('startdate'))\n",
        ")\n",
        "ogrn: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{prx_epk}{table['ogrn']}\")\n",
        "    .select(\n",
        "        F.col('documentnumber').cast(T.StringType()).alias('ogrn'),\n",
        "        'key',\n",
        "        'startdate'\n",
        "    )\n",
        "    .witnColumn('key_name', F.split('key', '\\.')[0])\n",
        "    .withColumn('rn', F.row_number().over(win_ogrn))\n",
        "    .filter(F.col('rn') == F.lit(1)).drop('rn')\n",
        "    .join(crmattributes, on='key_name', how='right_outer')\n",
        "    .drop('key', 'startdate')\n",
        ")\n",
        "\n",
        "# ИНН клиента\n",
        "win_inn: any = (\n",
        "    Window.partitionBy('key_name', 'inn').orderBy(F.desc('startdate'))\n",
        ")\n",
        "inn: DataFrame = (\n",
        "    spark.table(f\"{schema['epk']}.{table['inn']}\")\n",
        "    .select(\n",
        "        F.col('documentnumber').cast(T.StringType()).alias('inn'),\n",
        "        'key',\n",
        "        'startdate'\n",
        "    )\n",
        "    .witnColumn('key_name', F.split('key', '\\.')[0])\n",
        "    .withColumn('rn', F.row_number().over(win_inn))\n",
        "    .filter(F.col('rn') == F.lit(1)).drop('rn')\n",
        "    .join(ogrn, on='key_name', how='right_outer')\n",
        "    .drop('key', 'startdate', 'key_name')\n",
        ")\n",
        "\n",
        "# Сборка финального DataFrame\n",
        "assembling: DataFrame = (\n",
        "    inn\n",
        "    .withColumn('migration', F.concat_ws(' > ',\n",
        "                                         'system_name',\n",
        "                                         'migration_date')\n",
        "    )\n",
        "    .join(F.broadcast(dictionary_segment), on='key_segment',\n",
        "          how='left_outer')\n",
        "    .drop('key_segment')\n",
        "    .join(F.broadcast(dictionary_priority), on='key_priority',\n",
        "          how='left_outer')\n",
        "    .drop('key_priority')\n",
        "    .join(F.broadcast(dictionary_country), on='key_country',\n",
        "          how='left_outer')\n",
        "    .drop('key_country')\n",
        ")\n",
        "\n",
        "# Задаём порядок/структуру фрейма данных\n",
        "column_dict: dict = {\n",
        "    'eks_id': 'Уникальный идентификатор ЕКС',\n",
        "    'pprb_id': 'Уникальный идентификатор ППРБ',\n",
        "    'epk_id': 'Уникальный идентификатор ЕПК',\n",
        "    'name_org': 'Наименование клиента', 'inn': 'ИНН', 'ogrn': 'ОГРН',\n",
        "    'country_name': 'Страна клиента', 'segment': 'Сегмент',\n",
        "    'priority': 'Приоритет', 'number': 'Номер счёта',\n",
        "    'num_dog': 'Номер договора', 'begindate': 'Дата открытия счёта',\n",
        "    'lastchangedate': 'Дата последнего изменения',\n",
        "    'enddate': 'Дата закрытия счёта',\n",
        "    'prod_target': 'Целевое назначение договора',\n",
        "    'ptype_name': 'Наименование вида договора',\n",
        "    'currency_name': 'Валюта счёта',\n",
        "    'register_status_name': 'Статус счёта', 'register_type_name': 'Тип счёта',\n",
        "    'division': 'Подразделение',\n",
        "    'migration': 'Система миграции и дата миграции'\n",
        "}\n",
        "\n",
        "# Вносим корректировки и сохраняем результат в командное пространство\n",
        "createSchema(\n",
        "    column_dict, assembling.select(*column_dict).orderBy('begindate')\n",
        ").repartition(1).write.mode('overwrite').saveAsTable('stor.rko_showcase')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbf5113",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Обрабатываем sql-файл и используем его в качестве запроса.\n",
        "# Затем выгружаем результат в excel-файл.\n",
        "code_list: list = list(open('sql_request.sql'))\n",
        "sql_script: str = '\\n '.join(code_list)\n",
        "spark.sql(sql_script).toPandas().to_excel('crm.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1399ac55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Получение выписки со всеми операциями по необходимым клиентам.\n",
        "# Так как таблицы client и register будут использоваться много раз\n",
        "# без изменений, логичнее их кэшировать.\n",
        "# В данном скрипте используется метод оптимизации запроса через python-цикл.\n",
        "# Поскольку таблицы в скрипте наполнены огромным кол-вом данных,\n",
        "# чтобы избежать нагрузки \"бутылочного горлышка\" (bottleneck) и,\n",
        "# как следствие, увеличение плана запроса и падения производительности,\n",
        "# необходимо применить следующий вариант исполнения:\n",
        "\n",
        "# Получаем фрейм с необходимым списком клиентов\n",
        "client_list: DataFrame = pd.read_excel('org.xlsx', dtype=str)\n",
        "org_df: DataFrame = spark.createDataFrame(client_list)\n",
        "\n",
        "# БД\n",
        "database: dict = {\n",
        "    'stmnt': 'prx_collections_platform_data_api'\n",
        "}\n",
        "\n",
        "# Таблицы\n",
        "tables: dict = {\n",
        "    'client': 'pprb_platform_go_dataspace_client',\n",
        "    'register': 'pprb_platform_go_dataspace_register',\n",
        "    'turn': 'pprb_platform_go_dataspace_turn',\n",
        "    'docdata': 'pprb_platform_go_dataspace_docdata'\n",
        "}\n",
        "\n",
        "# Клиенты\n",
        "client: DataFrame = (\n",
        "    spark.table(f\"{database['stmnt']}.{tables['client']}\")\n",
        "    .select(\n",
        "        F.col('objectid').cast(T.StringType()).alias('client'),\n",
        "        F.col('ccepk').cast(T.StringType()).alias('epk_id'),\n",
        "        F.col('ccinn').cast(T.StringType()).alias('inn'),\n",
        "        F.col('cckpp').cast(T.StringType()),\n",
        "        'ccname'\n",
        "    )\n",
        "    .join(F.broadcast(org_df),\n",
        "          on=((F.col('epk_id') == org_df.epk_id)\n",
        "              & (F.col('inn') == org_df.inn)),\n",
        "          how='inner'\n",
        "    )\n",
        "    .dropDuplicates(['epk_id', 'inn'])\n",
        "    .cache() # Для более гибкой настройки лучше использовать persist().\n",
        "             # Сохранение в память:\n",
        "             #     df.persist(StorageLevel.MEMORY_ONLY) <- аналог cache()\n",
        "             # Сохранение на диск:\n",
        "             #     df.persist(StorageLevel.DISK_ONLY)\n",
        "             # Сохранение в память и на диск:\n",
        "             #     df.persist(StorageLevel.MEMORY_AND_DISK)\n",
        ")\n",
        "\n",
        "# Журнал записей\n",
        "register: DataFrame = (\n",
        "    spark.table(f\"{database['stmnt']}.{tables['register']}\")\n",
        "    .select(\n",
        "        F.col('objectid').cast(T.StringType()).alias('register'),\n",
        "        F.col('client').cast(T.StringType()),\n",
        "        F.col('ccaccnum').cast(T.StringType())\n",
        "    )\n",
        "    .join(F.broadcast(client), on='client', how='inner')\n",
        "    .drop('client')\n",
        "    .cache()\n",
        ")\n",
        "\n",
        "# Словарь названий столбцов БД/Excel\n",
        "column_dict: dict = {\n",
        "    'ccpurpose': 'Назначение платежа',\n",
        "    'ccdtacc': 'Счёт плательщика',\n",
        "    'ccdtbic': 'БИК плательщика',\n",
        "    'ccdtinn': 'ИНН плательщика',\n",
        "    'ccdtkpp': 'КПП плательщика',\n",
        "    'ccdtname': 'Наименование плательщика',\n",
        "    'ccdtnamebank': 'Банк плательщика',\n",
        "    'ccktacc': 'Счёт получателя',\n",
        "    'ccktbic': 'БИК получателя',\n",
        "    'ccktinn': 'ИНН получателя',\n",
        "    'ccktkpp': 'КПП получателя',\n",
        "    'ccktname': 'Наименование получателя',\n",
        "    'ccktnamebank': 'Банк получателя',\n",
        "    'ccstartsum': 'Входящий остаток на момент проводки',\n",
        "    'ccstartsumnat': 'Входящий остаток в нац. валюте',\n",
        "    'ccsum': 'Сумма проводки',\n",
        "    'ccsumnat': 'Сумма в нац. валюте',\n",
        "    'ccdt': 'Признак дебетования',\n",
        "    'ccdate': 'Дата проводки',\n",
        "    'ccaccnum': 'Номер счёта клиента',\n",
        "    'inn': 'ИНН клиента',\n",
        "    'ccname': 'Наименование клиента',\n",
        "    'epk_id': 'ЕПК клиента',\n",
        "    'cckpp': 'КПП клиента'\n",
        "}\n",
        "\n",
        "# Даты для разбивки плана запроса на 12 частей (1 год)\n",
        "list_of_dates: list = [\n",
        "    '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06',\n",
        "    '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12'\n",
        "]\n",
        "\n",
        "# Самые большие таблицы прогоняем через цикл по датам разбивки.\n",
        "# В качестве полей для фильтрации используем поля партиций: ctl_ccdate_part\n",
        "#                                                           ctl_ccdatedoc_part\n",
        "with pd.ExcelWriter('bank_statements.xlsx', engine='xlsxwriter') as writer:\n",
        "    for year_month in list_of_dates:\n",
        "        # Для детализации выполнения запроса делаем засечку по времени\n",
        "        create_date: any = dt.datetime.now()\n",
        "\n",
        "        # Проводка\n",
        "        turn: DataFrame = (\n",
        "            spark.table(f\"{database['stmnt']}.{tables['turn']}\")\n",
        "            .filter(\n",
        "                F.col('ctl_ccdate_part').like(f\"{year_month}%\")\n",
        "            )\n",
        "            .select(\n",
        "                F.col('objectid').cast(T.StringType()).alias('turn'),\n",
        "                'ccstartsum',\n",
        "                'ccstartsumnat',\n",
        "                'ccsum',\n",
        "                'ccsumnat',\n",
        "                'ccdt',\n",
        "                F.col('objectid').cast(T.StringType()).alias('register'),\n",
        "                'ccdate'\n",
        "            )\n",
        "            .join(F.broadcast(register), on='register', how='inner')\n",
        "            .drop('register')\n",
        "        )\n",
        "\n",
        "        # Документы\n",
        "        docdate: DataFrame = (\n",
        "            spark.table(f\"{database['stmnt']}.{tables['docdata']}\")\n",
        "            .filter(\n",
        "                F.col('ctl_ccdatedoc_part').like(f\"{year_month}%\")\n",
        "            )\n",
        "            .select(\n",
        "                'ccpurpose',\n",
        "                F.col('turn').cast(T.StringType()),\n",
        "                F.col('ccdtacc').cast(T.StringType()),\n",
        "                F.col('ccdtbic').cast(T.StringType()),\n",
        "                F.col('ccdtinn').cast(T.StringType()),\n",
        "                F.col('ccdtkpp').cast(T.StringType()),\n",
        "                'ccdtname',\n",
        "                'ccdtnamebank',\n",
        "                F.col('ccktacc').cast(T.StringType()),\n",
        "                F.col('ccktbic').cast(T.StringType()),\n",
        "                F.col('ccktinn').cast(T.StringType()),\n",
        "                F.col('ccktkpp').cast(T.StringType()),\n",
        "                'ccktname',\n",
        "                'ccktnamebank'\n",
        "            )\n",
        "            .join(turn, on='turn', how='inner')\n",
        "            .drop('turn')\n",
        "        ).toPandas().rename(columns=column_dict)\n",
        "        getExcel(writer, year_month, docdate)\n",
        "        # Ещё одна засечка в конце, вычисляем время выполнения подзапроса\n",
        "        # и выводим на экран с описанием даты и времени.\n",
        "        end_date: any = dt.datetime.now()\n",
        "        total_time: any = end_date - create_date\n",
        "        print(f\"Выписка за дату {year_month} готова через {total_time}\")\n",
        "\n",
        "# Очищаем кэш\n",
        "dataframes: list = [client, register]\n",
        "for df in dataframes:\n",
        "    df.unpersist()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
